<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>🧍‍♂️ Artificial Skin That Can Feel Touch: When Robots and Prosthetics Begin to “Feel”</title>
<link href="style.css" rel="stylesheet"/>
</head>
<body>
<header class="article-header">
<h1>🧍‍♂️ Artificial Skin That Can Feel Touch: When Robots and Prosthetics Begin to “Feel”</h1>
<p class="subtitle">
      The latest technologies allow artificial skin to sense pain, pressure, and heat —
      bringing robots and prosthetics closer to real human sensations.
    </p>
<img alt="Close-up of flexible electronic skin with embedded sensors glowing under touch" src="images/k1.jpg"/>
</header>
<article class="content">
<p>Imagine a person with a prosthetic arm being able to feel touch again —
    the warmth of a child’s hand, the texture of a wool sweater, or even the sting of a paper cut.</p>
<p>This isn’t science fiction — it’s the new reality of neurotechnology,
    where artificial skin can already sense pain, pressure, and temperature — and transmit it directly to the brain.</p>
<h2>🤖 What Is “Artificial Skin”</h2>
<p>Scientists call it <strong>electronic dermis</strong> (<strong>e-skin</strong>).
    It’s an ultra-thin, flexible material — often just 50 micrometers thick — made of silicone, graphene, or self-healing polymers,
    embedded with millions of micro-sensors that mimic human mechanoreceptors, thermoreceptors, and nociceptors.</p>
<p>These signals go to a microchip, which converts them into electrical impulses,
    and then — via a neural interface — directly into the human nervous system or the robot’s AI control core.</p>
<p>In other words, the skin doesn’t just “measure pressure” — it <em>feels</em>.</p>
<h2>⚙️ How It Works</h2>
<ul>
<li><strong>Sensory layer</strong>: piezoelectric and capacitive sensors detect touch, temperature (±0.1°C), and pain (via damage-detecting micro-cracks);</li>
<li><strong>Neural encoder</strong>: AI translates analog sensations into digital neural patterns identical to biological ones;</li>
<li><strong>Neurointerface</strong>: flexible nanowire arrays or optogenetic fibers transmit signals to peripheral nerves or the somatosensory cortex.</li>
</ul>
<p>AI plays a key role here —
    it teaches the system to recognize the <em>type</em> of touch: a soft stroke vs. a sharp prick,
    to distinguish velvet from sandpaper, and even to “remember” textures for 30 seconds — just like human skin does.</p>
<h2>🧠 Breakthrough: Artificial Skin from Seoul University</h2>
<p>In 2024, scientists from Seoul National University unveiled <strong>NeuroSkin v3</strong> —
    a material that mimics the sensitivity of human fingertip skin by <strong>95%</strong>.</p>
<ul>
<li>Detects temperature differences as small as <strong>0.1°C</strong>;</li>
<li>Registers pressure from <strong>0.01 kPa</strong> — lighter than a butterfly landing;</li>
<li>Features <strong>sensory memory</strong>: can “recall” the texture of an object 20 seconds after contact.</li>
</ul>
<p>This skin has already been tested on robotic hands and bionic prosthetics.
    In clinical trials, amputees connected through a Utah Slant Array interface
    reported sensations described as “almost indistinguishable from real skin” — including the ability to feel a pulse in a loved one’s wrist.</p>
<h2>🧬 Artificial Nerves</h2>
<p>To transmit touch to the brain, new-generation neurointerfaces are required.
    Researchers from Stanford and Caltech have created <strong>flexible carbon nanotube “nerves”</strong> that conduct signals
    <strong>100 times faster</strong> than previous polymer-based versions and integrate seamlessly with living tissue.</p>
<p>In live trials, patients could:
    <ul>
<li>Feel pressure in real time and adjust grip strength without visual feedback;</li>
<li>Distinguish between a grape and a cherry by touch alone;</li>
<li>Experience “phantom warmth” when holding a hot cup — a sensation lost for decades.</li>
</ul>
</p>
<p>This gives people back not only movement, but <strong>emotion</strong> — the ability to connect through touch.</p>
<h2>🦾 When Robots Feel</h2>
<p>Artificial skin is used not only in medicine.
    Robots with e-skin become <strong>safer and more empathetic</strong>:
    they can “understand” how firmly they’re holding a human hand,
    detect micro-damage in materials, and stop instantly upon sensing pain signals.</p>
<p>Industrial manipulators at Tesla’s Gigafactory now use e-skin to:
    <ul>
<li>Handle fragile battery cells without crushing them;</li>
<li>Detect micro-cracks in welds by “feeling” surface stress;</li>
<li>Work alongside humans with zero safety barriers.</li>
</ul>
</p>
<h2>⚠️ Problems and Challenges</h2>
<ul>
<li>Sensors degrade after <strong>6–12 months</strong> of continuous use — self-healing polymers are in development;</li>
<li>Transmitting complex sensations (like “wetness” or “tingling”) requires <strong>multi-modal AI encoding</strong>;</li>
<li>And the ethical question — <strong>“Can a robot experience pain?”</strong> — has sparked global debates on AI sentience.</li>
</ul>
<h2>🔮 The Future</h2>
<ul>
<li>Prosthetics that restore not only movement but <strong>pain, warmth, and tenderness</strong> — expected in clinics by 2027;</li>
<li>Robots that understand the boundaries of human contact and respond with appropriate gentleness;</li>
<li>Fully <strong>“tactile” avatars in the metaverse</strong> — where you’ll feel a virtual hug as if it were real.</li>
</ul>
<blockquote>“When a machine learns to feel, technology finally becomes truly human.”  
    <cite>— Dr. Hyeonwoo Lee, lead researcher, Seoul National University</cite></blockquote>
<hr/>
<div class="next-article">
<h2>📚 Next articles</h2>
<ul>
<li><a href="11.html">AI Created a Drug Faster Than a Pharma Company in 10 Years</a></li>
<li><a href="10.html">Smart Pills: Medicines That Think for Themselves</a></li>
<li><a href="7.html">Bionic Eye: How People Are Beginning to See Again</a></li>
<li><a href="6.html">“Liquid Human”: How Doctors Learned to Freeze People to Save Their Lives</a></li>
<li><a href="5.html">Glowing Plants: The Living Energy of the Future</a></li>
<li><a href="9.html">Scientists Created Blood That Can Save Anyone — Regardless of Type</a></li>
<li><a href="5.html">Sleep Chip: How Scientists Learned to Control Dreams</a></li>
<li><a href="4.html">Humans from Skin? Scientists Learned to Create Sperm and Eggs Without Donors</a></li>
<li><a href="8.html">Viruses Against Cancer: How Scientists Made Microbes Kill Tumors</a></li>
<li><a href="14.html">Blood That Heals Itself</a></li>

<li><a href="13.html">Food from Air: How Microorganisms Learned to “Cook” from Nothing</a></li>
<li><a href="12.html">The “Sleep Gene”: People Who Need Only 2 Hours to Feel Fully Rested</a></li>
<li><a href="2.html">Bacteria That Eat Plastic: Will Microbes Save the Planet?</a></li>
</ul>
</div>
</article>
<footer class="footer">
<p>© 2025 — Neuroscience and Future Technologies</p>
</footer>
</body>
</html>